# -*- coding: utf-8 -*-
"""
ğŸ“˜ Sahl Scraper API
-------------------
Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ ÙŠÙ†Ø´Ø¦ API Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flask Ùˆ BeautifulSoup
ÙŠÙ‚ÙˆÙ… Ø¨Ù‚Ø±Ø§Ø¡Ø© Ø¯Ø±ÙˆØ³ Ø£ÙŠ ØµÙ ÙˆÙ…Ø§Ø¯Ø© Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ø³Ù‡Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ (sahl.io)
Ø«Ù… ÙŠØ¹ÙŠØ¯ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¯Ø±ÙˆØ³ Ø¨ØµÙŠØºØ© JSON Ù„ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ù†Ù…ÙˆØ°Ø¬ GPT Ø¹Ø¨Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª (Actions)
"""

from flask import Flask, request, jsonify
import requests
from bs4 import BeautifulSoup

app = Flask(__name__)

@app.route("/sahl-scraper", methods=["POST"])
def scrape_sahl():
    data = request.get_json()
    grade = data.get("grade")     # Ù…Ø«Ù„: "Ø£ÙˆÙ„-Ø«Ø§Ù†ÙˆÙŠ"
    subject = data.get("subject") # Ù…Ø«Ù„: "ÙÙŠØ²ÙŠØ§Ø¡"

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
    url = f"https://sahl.io/sa/book/63/{grade}/{subject}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        res = requests.get(url, headers=headers, timeout=10)
        res.raise_for_status()
    except Exception as e:
        return jsonify({"error": f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {str(e)}"}), 500

    soup = BeautifulSoup(res.text, "html.parser")
    lessons = []

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯Ø±ÙˆØ³
    for link in soup.select("a.book-unit-link"):
        title = link.text.strip()
        href = link.get("href")
        if href:
            lessons.append({
                "title": title,
                "url": "https://sahl.io" + href
            })

    if not lessons:
        return jsonify({"message": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¯Ø±ÙˆØ³ Ù„Ù‡Ø°Ø§ Ø§Ù„ØµÙ Ø£Ùˆ Ø§Ù„Ù…Ø§Ø¯Ø©"}), 404

    return jsonify({
        "grade": grade,
        "subject": subject,
        "lesson_count": len(lessons),
        "lessons": lessons
    })


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)

# pip install flask requests beautifulsoup4
